A structured testing process is essential for conducting effective [[W7 - Concept Testing|concept testing]] and [[W7 - Usability Testing|usability testing]]. This process typically involves several key stages, from initial planning and preparation to moderating the sessions and finally, dealing with the outcomes and data collected.

**Tags:** #Week7 #UXTesting #TestingProcess #ResearchPlan #ParticipantRecruitment #Moderation #DiscussionGuide #DataCollection #UserFeedback

## Overview of the Testing Process

The testing process can be broken down into four main phases:

1.  **Plan:** Determine research objectives and/or hypotheses; plan your approach.
2.  **Prepare:** Recruit and schedule participants; prepare the discussion guide and test materials.
3.  **Moderate (Field):** Facilitate the testing session, build rapport, set the scene, and listen actively.
4.  **Outcomes:** Capture, synthesize, and share findings. (Analysis and reporting of outcomes are often covered in more detail in [[Week 03 - UX Analysis]]).

## 1. Plan: Defining Objectives and Approach

This initial phase is about laying the groundwork for the entire testing effort.

* **Determine Overall Objectives:** What do you want to learn from this testing?
    * **Assess:** Evaluate the usability of a design or the viability of a concept.
    * **Uncover & Understand:** Discover unknown issues, pain points, or user perspectives.
    * **Observe:** Watch how users interact with the design in realistic scenarios.
* **Formulate [[W7 - Hypothesis Generation and Testing|Hypotheses]] (if applicable):**
    * Develop specific, testable assumptions about user behavior, preferences, or the design's effectiveness.
    * Clearly define what you are trying to validate or disprove.
* **Choose Testing Methods:** Select the appropriate testing method(s) based on your objectives (e.g., moderated usability testing, unmoderated remote testing, A/B testing, concept walkthroughs).
    * The lecture mentioned "UNSW approved" methods like concept testing, service staging/role-play, and guerrilla testing, along with other methods like eye-tracking, focus groups, A/B testing, quantitative surveys, click testing, and 1:1 usability lab testing.
* **Develop a Test Plan:** A document outlining the goals, methods, participants, tasks, and metrics for the testing. (Similar to the research plan discussed in [[W2 - Starting Your UX Research (Planning & Preparation)#1 Plan Defining Learning Objectives and Scope|W2 - Research Planning]]).

## 2. Prepare: Setting Up for the Test

This phase involves all the logistical and content preparation needed to run the tests smoothly.

* **Participant Recruitment:**
    * **Target Market:** Define the characteristics of your ideal participants (should align with your [[W3 - Personas|personas]]).
    * **Sample Size:** Determine how many participants you need. For qualitative usability testing, the "Magic of 5 Users" is often cited (see [[W7 - Usability Testing#Magic of 5 Users|Moderation section below]]). For your group assignment workshop, 6-8 participants were required.
    * **Screening:** Develop criteria to ensure participants fit the project's target user profile.
    * **Sources for Finding Participants:** Colleagues (for informal/internal tests), friends & family (be mindful of bias), online survey panels, professional recruiters (e.g., Askable).
    * **Consent:** Always collect informed consent. This is an industry-standard practice and ethically crucial.
* **Create/Prepare Test Materials:**
    * This includes the [[W5 - Prototyping|prototype]], [[W5 - Wireframes|wireframe]], [[W4 - Ideation Techniques#Storyboarding in UX|storyboard]], or concept being tested.
    * Ensure materials are ready, functional (for prototypes), and presentable.
* **Develop a Discussion Guide (Test Plan/Script):**
    * **Purpose:** A structured guide for the facilitator to ensure consistency across sessions and that all key areas are covered.
    * **Key Sections (example structure from lecture):**
        1.  **Introduction & Warm-Up (e.g., 4 mins):** Introductions, set up, housekeeping, explain session purpose and expectations, engage the respondent, break the ice.
        2.  **Participant Context & Background (e.g., 10 mins):** Understand background context about the participant, their role, and experiences relevant to the test.
        3.  **Current State / Task Performance (e.g., 25 mins):** Guide the participant through specific tasks. Observe their actions and listen to their thoughts.
        4.  **Exploring the Ideal Experience / Feedback on Concepts (e.g., 20 mins):** Gather feedback on the design, specific features, or overall experience.
        5.  **Thank You & Close (e.g., 1 min):** Get final thoughts, thank the participant.
    * **Important Note:** The guide covers topic areas, but wording and sequencing can be flexible to maintain a conversational atmosphere. Not all areas may be relevant for every participant.
* **Creating a Test Plan (Key Instructions for Participants - from lecture slide):**
    1.  "We are not testing you, we are testing our designs." (Reassure the participant).
    2.  "Please be as candid as possible." (Encourage honest feedback).
    3.  "Please think out loud as you navigate..." (Essential for understanding their thought process).
    4.  "I might not be able to help you or answer some of your questions." (To keep the test realistic).
    5.  "This isn't a real website, it's a mock-up..." (Set expectations about functionality).
    * Always ask if they have questions before beginning.

## 3. Moderate (Field): Facilitating the Session

This is the execution phase where the actual testing with participants takes place.

* **Building Rapport:** Make the participant feel comfortable and at ease.
* **Setting the Scene:** Clearly explain the purpose of the session, what will happen, and how their feedback will be used. Reiterate key points from the test plan instructions.
* **Active Listening & Observation:** Pay close attention to what participants say (verbal feedback) and do (behavior, non-verbal cues).
* **Facilitation Rules/Guidelines (from lecture):**
    1.  **Be Curious:** Listen with "fresh ears," explore the unexpected, avoid confirming your own biases.
    2.  **Listen More Than You Talk:** Your goal is to learn, not to inform or convince.
    3.  **Be Yourself, Be Authentic:** If you're not comfortable, the participant won't be either.
    4.  **Be Aware Of Your Surroundings:** Consider the physical environment and privacy.
    5.  **Base In Actual Behaviour:** Focus on what participants *do* and their past experiences, not hypothetical future actions. (Ask "When is the last time you have...?" instead of "Would you...?").
    6.  **Ask Open, Expansive Questions:** (e.g., "Tell me more...?", "What was it about this that you liked...?").
    7.  **Don't Be Afraid Of Silences:** Give people time to think and elaborate.
    8.  **Don't Be Weird:** Avoid making participants uncomfortable (e.g., don't challenge, judge, appear controlling or bored).
* **Magic of 5 Users (Nielsen Norman Group finding):**
    * Testing with just 5 users can typically uncover about 85% of the usability problems in an interface (assuming the probability of a user encountering an error is ~31%).
    * Returns diminish drastically after 5 users (e.g., 3 users catch ~65%, 4 users ~75%, 6 users ~90%).
    * **Importance:** Helps ensure resources are not wasted on over-testing, and allows for quick iteration cycles. Most major issues can be identified with a small sample.
* **Note-Taking:** Have a dedicated note-taker if possible, so the facilitator can focus on the participant.

## 4. Outcomes: Capturing and Synthesizing Findings

After the testing sessions, the collected data needs to be processed.

* **Collecting Data:**
    * **Quantitative Data:** Measurable data (e.g., number of clicks, time to complete a task, success/failure rates, [[W7 - Measuring Usability|usability scores like SUS]]).
    * **Qualitative Data:** Non-numerical data (e.g., overall impressions, likes/dislikes, direct quotes, observed behaviors, inferred responses like confusion or frustration).
* **Capturing Feedback Systematically:** Use a structured way to document observations for each participant. A template might include:
    * Context
    * Stated Response (what they said)
    * Observed Response (what they did, non-verbal cues)
    * Inferred Response (e.g., "user appears confused")
    * Overall Impressions
* **Participant Snapshots:** Create summaries for each participant, including:
    * Sketch/Image (optional, with consent)
    * Memorable quotes or comments.
    * A summarizing hashtag (e.g., "#TechSavvyButFrustrated").
    * Important/differentiating profile information (Participant ID, location, key characteristics).
    * 3 most interesting things heard (new news, different perspectives, insights/themes).
* **Synthesizing Findings:** Use techniques like [[W3 - Affinity Mapping|Affinity Mapping]] to group observations and identify patterns, themes, and key insights.
* **Focus on What's Important (IRA):**
    * **[[W3 - Analysis and Synthesis in UX#Generating Insights|Interesting]]:** How did the user's perspective change yours?
    * **[[W3 - Analysis and Synthesis in UX#Generating Insights|Relevant]]:** Is it useful in answering research questions or explaining something further?
    * **[[W3 - Analysis and Synthesis in UX#Generating Insights|Actionable]]:** How will this observation be used to change behavior or inform design? Does it provide new thinking or certainty?
* **Sharing Findings:** Prepare a report or presentation to communicate key insights and recommendations to the team and stakeholders.

**Avoiding Bias in Testing:**
* Note down your assumptions beforehand.
* Choose representative participants.
* Structure your test plan/guide appropriately to avoid leading questions.
* Be open to perspectives from peers and other research.
* Strive to be an "objective sponge," soaking up information without immediate judgment.
* Be aware of potential biases: Confirmation bias, Social desirability bias, Hawthorne effect, Culture bias.

A well-executed testing process provides invaluable feedback for creating user-centered and effective designs.

---
**Parent Topic:** [[Week 07 - UX Testing]]
**Previous Topic:** [[W7 - Usability Testing]]
**Next Topic:** [[W7 - Hypothesis Generation and Testing]]
**Overall Course Context:** [[INFS3700 UX & IT Service Design - Main Summary]]